!!! XML
!!!
%div#12-chapter.chapter{:xmlns=>"http://www.w3.org/1999/xhtml"}
  %h1 La rupture Agile
  :markdown  

    Citons l'histoire officielle (dans la traduction qu'en propose Fabrice Aimetti):

    > Du 11 au 13 Février 2001, dans l'hôtel The Lodge de la station de ski Snowbird située dans les montagnes Wasatch de l'Utah, dix-sept personnes se sont réunies pour parler, skier, se détendre, essayer de trouver un terrain d'entente et bien sûr, manger. Ce qui en est sorti s'appelle le Manifeste du Développement Agile de Logiciels. Y participèrent des représentants de l'Extreme Programming, de SCRUM, de DSDM, de l'Adaptive Software Development, de Crystal, du Feature-Driven Development, du Pragmatic Programming, et d'autres personnes sensibles à la nécessité de trouver une alternative aux pesants processus de développement logiciel pilotés par la documentation.

    Le ton est donné: le mouvement Agile se positionne d'emblée en réaction à une situation jugée insatisfaisante, et qui trouve pourtant son inspiration aux racines de la discipline du Génie Logiciel: les "processus de développement" sont excessivement "pilotés par la documentation".

    Mais pourquoi cette approche "Agile" devient-elle une alternative, pourquoi à ce moment? Et surtout, comment la caractériser?

    ## Théorie de la Rupture

    La théorie de la rupture est due à Clayton Christensen qui la présente en 1997 dans [The Innovator's Dilemma](http://www.amazon.fr/Innovators-Dilemma-Technologies-Cause-Great/dp/0875845851). Le sous-titre, éloquent, avertit du risque que présentent certaines innovations ou "ruptures technologiques": "lorsque de nouvelles technologies entraînent la chute de grandes entreprises".
    Christensen distingue deux types d'innovation, l'innovation de continuité et l'innovation de rupture. La première est caractérisée par des produits qui renforcent, dans le contexte concurrentiel, la position dominante des acteurs déjà bien placés sur ce marché: ces produits sont jugés sur des critères de performance déjà reconnus. Imaginez par exemple la dernière génération des appareils photos numériques, qui passent de 8 à 12 megapixels. (Une innovation "révolutionnaire" n'est pas nécessairement une rupture en ce sens, ainsi l'article Wikipedia consacré à la théorie précise que l'automobile fut une révolution mais pas, dans ses effets sur les acteurs de l'économie industrielle, une véritable rupture.)

    L'innovation de rupture se caractérise par l'ouverture de nouveaux marchés, et la mise en danger des acteurs dominants dans un marché donné; elle propose quelque chose d'inattendu en décalage avec les critères de valorisation dominants.
    L'histoire de la photo numérique à ses débuts est à ce titre éclairante, sa victime emblématique étant Polaroid, l'un de ces noms de marque passés dans l'usage courant, tant son emprise sur un important segment du marché était complète. Pourtant, en 2001 Polaroid se mettait en faillite, pour ne renaître de ses cendres qu'à la suite du rachat de la marque et presque uniquement de cela par des investisseurs cherchant à profiter d'une image encore favorable.

    Pourtant, seulement dix ans plus tôt, bien malin qui aurait pu prédire à la photographie le bel avenir qui est devenu notre présent: disparition inéluctable non seulement des modèles argentiques mais également de tout un secteur d'économie qui en dépendait, comme les petites boutiques qui assuraient le développement de nos "péloches".
    Ainsi en 1991 le modèle Fotoman, est selon une critique pourtant lucide "incapable de produire des images de qualité professionnelle". En noir et blanc et d'une résolution maximum de 320x240, il coûte la bagatelle de 1000$. Ce n'est en fait qu'un gadget, conseillé aux personnes qui souhaitent s'amuser sur leur PC à triturer et retoucher leurs photos.
    Comment un tel produit arrive-t-il, petit à petit, à s'imposer jusqu'à vingt ans plus tard avoir totalement détrôné la génération précédente? Pour avoir un début de réponse, il faut comprendre que les acteurs dominants du marché le sont en vertu de l'excellence de leurs produits selon des critères de performance appréciés par la clientèle: en l'occurrence, la finesse de l'image, le bon rendu des couleurs, etc. De ce point de vue la photo numérique présente des avantages (facilité de stockage, moins d'usure mécanique, manipulation numérique) mais ceux-ci ne sont pas suffisant pour l'emporter face aux concurrents dominants.
    Oui, mais certains marchés n'ont que faire de ces critères de performance majeurs. Parmi les premiers clients auxquels s'adresse le numérique on trouve des fabricants d'avions, qui doivent prendre leurs appareils sous toutes les coutures pendant leur construction pour des raisons règlementaires, et vont donc faire des économies considérables sur le développement chimique, mais ne se soucient guère d'une résolution très fine. Ou bien encore des journalistes qui vont privilégier la transmission rapide d'une information brûlante mais ne sont que peu handicapés, compte tenu des qualités d'impression, par une résolution limitée ou par le noir et blanc.
    L'innovation de rupture est donc portée par des produits initialement totalement inadéquats quand on les juge à l'aune des critères de performance établis, mais qui vont conquérir un marché de niche puis se développer. L'innovation plus classique, "de continuité", permet progressivement à ces produits de rattraper tout ou partie de leur retard sur ces critères dominants, et c'est ainsi qu'ils peuvent finir par mettre en danger les leaders du marché.

    Alors, en quoi le débat entre "Génie Logiciel" et "Agile" peut-il être considéré comme une instantiation de ce modèle? Certes, il faut faire preuve d'un peu de prudence: considérer l'un et l'autre comme des "produits" en concurrence sur un "marché" relève, sinon de la métaphore, d'une moins d'une interprétation assez libre de ces termes. Je trouve pourtant que le modèle s'applique plutôt bien, et permet d'expliquer non seulement le succès initial de l'approche Agile mais également ses évolutions au cours des dernières années. (Evolutions qui sont souvent mal connues des personnes qui pratiquent ces approches et même de certains experts: toujours ce blocage sur l'histoire...)        L'idée est donc d'analyser le Génie Logiciel comme le produit dominant, et d'expliquer cette domination par le fait qu'il répond aux critères exigés par le marché. L'histoire du projet Chorus nous suggère que "le succès du projet" ne fait pas nécessairement partie de ces critères... alors quels sont-ils? Selon quel critère de performance le discours classique du Génie Logiciel, issu des conférences de 1968 et 1969, est-il, malgré ces échecs, jugé satisfaisant, à tel point qu'on enseigne encore le cycle en V dans les universités?            Pour obtenir une réponse, il faut se repencher sur les origines du Génie Logiciel dans la "crise du logiciel". Celle-ci se manifeste initialement par des difficultés à fournir des prévisions fiables quant aux projets, souvent liées à des allers-retours autour des exigences. Le critère de performance exigé de tout ce qui se présente comme une solution à ladite crise est, en un mot, la possibilité de contrôler tout aléa. On va privilégier la traçabilité, la documentation, et le respect des contraintes que ces outils permettent de suivre le mieux: délais (et donc coûts) maîtrisés, spécifications respectées.    ## "Ça ne peut pas marcher"    Cette phrase qui constitue le leitmotiv d'un des chapitres du livre de Kent Beck illustre bien en quoi l'approche Agile joue le rôle du produit "gadget", totalement insuffisant, dans l'analogie avec la photo numérique autour des années 1990.    Planifier en permanence, itérativement, ça ne peut pas marcher, on ferait peur au client (pas assez de contrôle). Mettre une nouvelle version en exploitation tous les mois ou deux, ça ne peut pas marcher, on ferait peur aux utilisateurs (pas assez de contrôle). Démarrer le développement avec une vision architecturale résumée en une métaphore, ça ne peut pas marcher, et si on s'était trompés? (Pas assez de contrôle.) Ne pas anticiper sur les besoins futurs lors de la conception, ça ne peut pas marcher, on se retrouvera coincés (pas assez de contrôle). Faire écrire les tests par les programmeurs, ça ne peut pas marcher, tout le monde sait que les programmeurs ne peuvent pas tester leur propre travail et que le test est une profession à part entière (pas assez de spécialisation, donc de contrôle). Travailler en binômes, ça ne peut pas marcher, ça va prendre deux fois plus longtemps, et ils risquent de ne pas s'entendre (pas assez de contrôle, mais aussi une vision du développement comme activité mécanique, réduite à la saisie de code au clavier).    Pour la plupart ces arguments sont légitimes, de même qu'il est légitime de condamner en 1990 la nouvelle technologie numérique comme tout à fait inadéquate.    ## Valeurs classiques contre valeurs agiles    L'approche Agile quand à elle est initialement destinée à des projets qui ne se soucient que très peu de contrôler et de tracer. On privilégie la communication directe et orale avec le client, lui permettant d'ajuster sa demande en temps réel; la qualité du produit et sa pertinence pour répondre aux besoins réels (plus qu'à ceux exprimés), la maîtrise des priorités fonctionnelles sous contrainte de délais.    Ne pas chercher à faire concurrence aux "méthodologies" dominantes et aux approches de management orientées sur les production documentaires de ces dernières permet aux "agilistes" comme on ne les appellera que plus tard de s'affranchir de nombreuses contraintes, et d'inventer un mode de développement très souple, basé sur des itérations courtes régies par la règle du "timebox" (on cherche à en faire le maximum en temps imparti plutôt qu'à terminer un objectif fixe quitte à jouer les prolongations), décomposé par incréments fonctionnels. Les phases amont et le travail documentaire sont réduits à l'essentiel, c'est-à-dire à ce qui permet à l'équipe de partager une même compréhension de l'objectif. Le chef de projet perd ses prérogatives: il n'attribue plus les tâches et ne joue plus les intermédiaires, le client étant présent sur place. Des dispositifs techniques (automatisation des tests, intégration continue) limitent au minimum les coûts d'intégration et de refonte.    Une métaphore souvent employée compare l'équipe Agile à des musiciens de jazz qui improvisent, par rapport à leurs collègues dans une formation classique: l'absence de contrôle n'implique pas moins de technicité, et de satisfaction procurée par le résultat final.    Une recherche textuelle dans les actes des conférences de l'OTAN (NATO1968), comparée à la même recherche (grâce à Google Books) dans les actes de la conférence européenne sur XP et les processus agiles (XP2008) permet d'objectiver quelque peu ces différences de valeurs:    * le mot-clé "control" apparaît plus de 100 fois dans NATO1968, 27 fois dans XP2008 (et souvent dans le contexte "groupe contrôle vs groupe expérimental", pour les papiers scientifiques    * le mot-clé "team" apparaît plus de 100 fois dans XP2008, seulement 17 fois dans NATO1968    * le mot-clé "skill" apparaît seulement 5 fois dans NATO1968, 15 fois dans XP2008    * le mot-clé "motivation" apparaît seulement une fois dans NATO1968 ("la motivation de cette conférence..."), 12 fois dans XP2008 et pour la plupart au sens "motivation de l'équipe"    Le critère de performance privilégié par l'approche Agile, ce n'est plus le contrôle, mais bien l'exploitation du talent individuel et collectif. Lorsque les approches Agiles se font connaître sous ce nom, en 2001, ces valeurs sont codifiées sous la forme du fameux Manifeste Agile.    ## Agile, dix ans après    Mais depuis 2001, les pratiques ont évolué: le challenger Agile a progressé sur plusieurs critères de performance y compris ceux reconnus par le modèle dominant. C'est exactement ce que prédit la théorie de la rupture, pourtant cette évolution est en grande partie invisible, très peu reconnue par les professionnels qui ont rejoint la communauté récemment et ignorée même d'un certain nombre de vétérans. (Ou bien, elle se traduit pour certains par un inconfort, un sentiment que "Agile c'est devenu n'importe quoi".)    Plusieurs pratiques considérées désormais comme au coeur de Scrum sont ainsi apparues depuis 2001, postérieurement au terme “Agile” lui-même: par exemple les Rétrospectives et le Task Board, deux pratiques très proche du "noyau" mais pourtant d'importation relativement récente. Quant à Extreme Programming son statut de "work in progress" est acquis depuis la deuxième édition du livre de Kent Beck.    Des pratiques sont apparues pour combler par exemple des lacunes dans la prise en compte de l'ergonomie par les approches Agiles, ou encore pour donner des directives plus précises sur la façon d'organiser les "phases amont", le recueil des exigences: on parle de Personas, de Charte Projet, de Story Mapping.    Initialement vécue comme une obligation déraisonnable, la pratique Extreme Programming désignée à l'origine par le conseil "faites écrire vos tests de recette par le client" a beaucoup évolué et donné naissance à des écoles et appellations diverses: ATDD ou pilotage par les tests client, BDD ou Spécifications Exécutables. Bien que ce sujet soit actuellement en pleine fermentation, une tendance se dégage clairement: ces évolutions commencent à répondre de façon satisfaisante aux exigences de formalisation et de traçabilité qui sont l'apanage des organisations les plus exigeantes en termes de contrôle.    Des pans entiers de pratiques ont enfin servi à occuper de nouveaux terrains. En 2001, Scrum et XP se focalisent sur de petites équipes colocalisées dont la préoccupation presque exclusive est le développement dans un contexte projet: la "date de fin" est une des préoccupations majeures, on conçoit le projet comme un effort unique au-delà duquel l'équipe passe à autre chose.    Ce n'est qu'au fil du temps que la recherche d'adaptation des approches agiles à d'autres contextes conduit à explorer des pratiques alternatives. Ainsi l'approche Lean et Kanban peut-elle trouver un terrain d'application fertile parmi les équipes chargées de maintenance ou de TMA. La communauté Agile voit aussi se développer des mouvements visant à repenser d'autres métiers, à l'image de DevOps qui réunit des admin systèmes sensibles aux évolutions du développement.

    ## Agile dans dix ans?
    En 2010, la photo numérique a entièrement remplacé la technologie précédente (et une nouvelle mutation s'amorce, celle du cinéma, mais c'est une autre histoire). Peut-on imaginer un avenir comparable pour les approches Agiles? Il convient de rester prudent. D'une part, on apprend vite quand on s'intéresse à l'histoire et à la sociologie des sciences et des techniques que le progrès n'est jamais gagné d'avance. Rejeté par toute la communauté médicale de son temps, Semmelweiss ne fut reconnu comme un pionnier de l'hygiène médicale qu'après avoir été poussé à une dépression nerveuse qui lui fut fatale. Il faut du temps, beaucoup de travail et sans doute un peu de chance pour qu'une idée s'impose de manière irréversible; le plus simple est sans doute encore de considérer que tout est réversible.
    Il existe une autre raison d'être prudent: le statut de "challenger" ne confère pas automatiquement l'infallibilité de ceux qui se rangent sous sa bannière. Comme le disait Carl Sagan: "They laughed at Columbus, they laughed at Fulton, they laughed at the Wright brothers. But they also laughed at Bozo the Clown." On s'est moqués de Christophe Colomb, de Robert Fulton - l'inventeur du bateau à vapeur - des frères Wright, et de Semmelweiss.

    Mais on s'est aussi moqués de tout un tas de gugusses que l'histoire a eu bien raison d'ignorer.

    Notamment, certaines lacunes persistantes continuent à plomber la communauté Agile, et risquent de mettre en péril l'avenir du sujet.